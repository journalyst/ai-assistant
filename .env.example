# Journalyst AI Assistant - Example Environment Configuration
# Copy to .env and adjust values. Environment variable precedence: real env vars > .env file > defaults.

# Runtime
ENVIRONMENT=dev
DEBUG=true

# Postgres (write connection used only by parent app; assistant uses read-only)
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=journalyst_test
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_READONLY_USER=readonly_user
POSTGRES_READONLY_PASSWORD=your_readonly_password_here

# Redis
REDIS_URL=redis://localhost:6379/0

# QDrant
QDRANT_URL=http://localhost:6333

# OpenAI / Compatible Provider Keys
OPENAI_API_KEY=sk-your-openai-key
OPENROUTER_API_KEY=or-your-openrouter-key

# Embeddings Configuration
# EMBEDDING_PROVIDER options: "local" (transformers) or "openai" (API)
EMBEDDING_PROVIDER=local
# For local: sentence-transformers/all-MiniLM-L6-v2, BAAI/bge-small-en-v1.5, sentence-transformers/all-mpnet-base-v2
# For openai: text-embedding-3-small, text-embedding-ada-002
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384
# Device: "cpu" or "cuda" (GPU)
EMBEDDING_DEVICE=cpu

# Mini LLM model for routing (OpenAI-compatible naming)
ROUTER_MODEL=meta-llama/llama-3.3-70b-instruct:free

# Primary Analysis Model
ANALYSIS_MODEL=meta-llama/llama-3.3-70b-instruct:free

# Optional reasoning model (if available)
REASONING_MODEL=google/gemma-3-27b-it:free

# Rate limiting (simple)
RATE_LIMIT_REQUESTS_PER_MINUTE=60
